# Contributing to ezr

> Semi-supervised explanations for incremental multi-objective optimization

Thanks for your interest in contributing! This project demonstrates that sophisticated optimization can emerge from remarkably simple algorithms. We embrace the "Less, but Better" philosophy.

## Project Principles

- **Readable**: Minimal lines, clear naming, inline documentation
- **Fast**: No heavy libraries (no pandas or sklearn); lightweight and efficient  
- **Testable**: Each function should be independently testable
- **Purposeful**: Features support core goals: explainable reasoning, optimization, and small-data learning

## Code Structure

ezr consists of ~500 lines in a single Python file organized into logical sections:

| Section | Functions | Purpose |
|---------|-----------|---------|
| **Data Types** | `Num`, `Sym`, `Cols`, `Data` | Core data structures and column summarizers |
| **Incremental Updates** | `add`, `sub`, `adds` | Welford's method for incremental statistics |
| **Distance Metrics** | `dist`, `disty`, `distx`, `distysort` | Multi-objective distance calculations |
| **Active Learning** | `likely`, `nearer`, `likelier` | Elite greedy search with âˆšN sampling |
| **Explanation Trees** | `Tree`, `treeCuts`, `treeShow` | Minimal decision trees for interpretability |
| **Utilities** | `csv`, `shuffle`, `coerce` | File I/O and data processing |

**Key Design Patterns:**
- Uses `o()` (SimpleNamespace) instead of classes
- Docstring-based configuration via regex parsing
- 7-15 lines per function is typical
- Everything incrementally updatable for speed

## Development Setup

```bash
git clone https://github.com/timm/ezr
cd ezr
python3 -B ezr.py -h

# Get test data
git clone http://github.com/timm/moot
python3 -B ezr.py -f ../moot/optimize/misc/auto93.csv
```

## Contributing Guidelines

### Style Guide

- Prefer one-liners when readable
- Avoid external dependencies unless essential
- Use meaningful short names (`num`, `sym`, `row`, `col`)
- Write short functions (aim for 7-15 lines)
- Use type hints: `Number = int|float`, `Row = List[Atom]`

### Core Algorithm (A,B,C Pattern)

When modifying the optimization logic, understand the pattern:
- **A=Any**: Start with 4 randomly labeled examples
- **B=Budget**: Label up to B total examples using elite search  
- **C=Check**: Test top 5 predictions, return best result

### Testing

The main file includes a `demo()` function that runs the complete workflow:

```python
def demo():
    data = Data(csv(the.file))
    # ... complete example workflow
```

Add test functions using the existing pattern:
```python
def eg_your_test():
    "Description of what this tests"
    # your test code here
    assert something_works()
```

### Key Functions to Understand

- `likely()`: Main active learning loop
- `nearer()`: Distance-based acquisition  
- `likelier()`: Bayesian likelihood acquisition
- `Tree()`: Builds explanation trees
- `disty()`: Distance-to-heaven scoring

### Performance Expectations

The tool should maintain:
- Sub-100ms typical runtimes
- ~3 seconds for large datasets (128 attributes, 100K rows)  
- 60%/74%/90% of optimal with just 12/25/50 labeled samples

## Documentation

The README.md uses a specific structure - when adding features, update:
- **Motivation**: The labeling problem and "funneling" principle
- **Performance**: Concrete numbers from 118 test datasets
- **Algorithm**: A,B,C pattern pseudocode
- **Background**: Research backing (Adams et al. subtractive changes, CACM funneling)

## Before You Commit

- Run `python3 -B ezr.py` to ensure it works
- Test with different `-a` acquisition modes (near, xploit, xplor, bore, adapt)
- Verify performance hasn't regressed on your test datasets
- Keep the single-file structure - resist urge to split into modules
- No trailing whitespace, unnecessary comments, or debug prints

## Philosophy

This project challenges the "bigger is better" assumption in AI. We show that:
- 5% of SE papers consider alternatives to LLMs (methodological oversight)
- Simple methods often outperform "Big AI" (100x faster with greater accuracy)
- Human-AI partnership through explainable, auditable reasoning
- Software exhibits "funneling" - complex behavior converges to few outcomes

## Questions?

Create an issue or open a draft PR. We value simplicity over sophistication, and explanation over black-box optimization.
